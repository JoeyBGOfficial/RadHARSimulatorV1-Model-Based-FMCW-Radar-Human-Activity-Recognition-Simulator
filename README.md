# RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator

## I. INTRODUCTION

![RadHARSimulator_Splash_Screen](https://github.com/user-attachments/assets/18dcaaab-0d71-4fc6-9c33-1a26986dd447)
Fig. 1. Splash screen of RadHARSimulator V1.

### Write Sth. Upfront:

The paper of this simulator can be found here: https://arxiv.org/abs/2509.06751.

From the very beginning of my research, I had planned to develop simulation software. This simulator consumed nearly a full year of my spare time. It involved countless hours of grueling debugging, but thankfully, I persevered and successfully made it.

I would like to thank my mentors for the platform they have provided me. I would also like to thank my fellow Xiaolong Sun and junior mate Jiarong Zhao. It was their encouragement that kept me going and enabled me to complete this work.

My software has not undergone extensive testing by a large number of users. There may still be areas for improvement during use. I welcome your valuable feedback and would be very grateful!

### Basic Information:

The V1 version of radar-based human activity recognition simulator (RadHARSimulator). This software provides a streamlined end-to-end simulation and analysis pipeline for FMCW radar human activity recognition. 12 activities, wall target, and all parameters of both radar system and human kinematic can be adjustable.

**My Email:** JoeyBG@126.com;

**Abstract:** Radar-based human activity recognition (HAR) is a pivotal research area for applications requiring non-invasive monitoring. However, the acquisition of diverse and high-fidelity radar datasets for robust algorithm development remains a significant challenge. To overcome this bottleneck, a model-based frequency-modulated continuous wave (FMCW) radar HAR simulator is developed. The simulator integrates an anthropometrically scaled $13$-scatterer kinematic model to simulate $12$ distinct activities. The FMCW radar echo model is employed, which incorporates dynamic radar cross-section (RCS), free-space or through-the-wall propagation, and a calibrated noise floor to ensure signal fidelity. The simulated raw data is then processed through a complete pipeline, including moving target indication (MTI), bulk Doppler compensation, and Savitzky-Golay denoising, culminating in the generation of high-resolution range-time map (RTM) and Doppler-time maps (DTMs) via both short-time Fourier transform (STFT) and Fourier synchrosqueezed transform (FSST). Finally, a novel neural network method is proposed to validate the effectiveness of the radar HAR. Numerical experiments demonstrate that the simulator successfully generates high-fidelity and distinct micro-Doppler signature, which provides a valuable tool for radar HAR algorithm design and validation.

**Corresponding Papers:**

[1] W. Gao, “RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator,” $arXiv~Preprint$, Sep. 2025, doi: 10.48550/arXiv.2509.06751.

### Notes:

**This simulator is currently available for installation only. If you require access to the source code, please contact the author to obtain permission.**

## II. HOW TO INSTALL

Follow the steps for installing the simulator.

1. Download the installation .exe file for the corresponding version.
2. Run .exe file.
3. After the installation package initializes, proceed to the introduction page and select "Next". <img width="1690" height="1250" alt="image" src="https://github.com/user-attachments/assets/20b6e746-9042-4b04-915e-dfef0bb24336" />
4. Choose the folder you want to install, and select "Next". <img width="1690" height="1250" alt="image" src="https://github.com/user-attachments/assets/a7137b87-c45b-4cbd-a536-1b5ed434e602" />
5. Make sure to install both the simulator and MATLAB Runtime R2025a, and select "Starting Installation". <img width="1690" height="1250" alt="image" src="https://github.com/user-attachments/assets/af7dbf8a-d08e-4f94-9d39-1d9b9ff285e7" />
6. Select "Close" and finish the installation. <img width="1690" height="1250" alt="image" src="https://github.com/user-attachments/assets/4d0c44a8-dadc-47d4-82d9-e7ce61060e4c" />
7. Within the application subfolder of your installation directory, you will find the software's launch button. Additionally, data generated by the software's simulation will be stored here. <img width="2136" height="1366" alt="image" src="https://github.com/user-attachments/assets/ae1f06ec-b524-41ae-a90c-507d8ead44c2" />

## III. HOW TO USE

![wechat_2025-09-08_165709_994](https://github.com/user-attachments/assets/15860457-59a0-4e1a-9331-789ce891b373)

Fig. 2. Software interface of the proposed simulator.

After running the launch botton, you will see the interface of the software. Hovering the mouse over the corresponding parameter box displays an explanation of the parameter to be entered and its unit. After filling in the parameters, switch the “off” button to “on” to start the simulation. Upon simulation completion, the parameters, echo matrix, and various images will automatically pop up.

You can also access the software manual by tapping the “Instruction of the Software” button.

## IV. ABOUT THE NETWORK MODEL

### A. Theory in Simple

For the task of radar-based HAR from DTMs, a novel neural network architecture is designed shown in Fig. 3. The core principle of this design is the replacement of the computationally intensive self-attention mechanisms commonly found in ViT with FFT-based global filter module. This module is engineered to facilitate the exchange of information across all spatial locations of the feature maps by operating in the frequency domain. The architecture is constructed to improve training stability and lightweight performance.

![FFTBasedNN](https://github.com/user-attachments/assets/8685098e-6d8a-4014-8b01-666a2ec88e6b)

Fig. 3. Structure of the proposed FFT-based neural network model.

### B. Codes Explanation (Folder: FFTBasedNN)

#### 1. FFTBasedNN.m ####

This MATLAB script implements the FFT-Based recognition model for radar HAR. It loads a dataset of DTM, constructs a custom neural network architecture incorporating FFT-based global filter layers, trains the model using specified options, and performs post-training analysis including visualization of accuracy/loss curves, positional embeddings, and learned global filters.

**Input:** Dataset directory ('dataset/') containing subdirectories for each class with DTM images.

**Output:** Trained model weights ('best_model.mat', 'final_model.mat'), console logs, 'curves.png' (training/validation curves), 'heatmaps.png' (positional embeddings), 'filter_map.png' (learned global filters).

#### 2. FFTBasedNN_Improved.py ####

This Python script using Paddlepaddle framework implements an improved version of the FFT-Based recognition model for radar HAR. It defines a custom dataset class, constructs the model with global filter layers, trains the model with label smoothing and AdamW optimizer, and visualizes training curves, positional embedding heatmaps, and learned global filters.

**Input:** Dataset directory ('dataset/') containing subdirectories for each class with DTM images.

**Output:** Trained model weights ('best_model.pdparams', 'final_model.pdparams'), console logs, 'curves.png' (training/validation curves), 'heatmaps.png' (positional embeddings), 'filter_map.png' (learned global filters).

#### 3. JoeyBG_FFTLayer.m ####

This MATLAB custom deep learning layer class defines the 'JoeyBG_FFTLayer', which implements the core global filtering operation in the frequency domain. It includes forward propagation using FFT, element-wise multiplication with learnable complex weights, and IFFT, as well as a custom backward function to handle complex gradients for compatibility with MATLAB's optimizers.

**Input:** Feature maps from previous layers; dimensions [Height, Width, Channels] specified during initialization.

**Output:** Filtered feature maps in the spatial domain with real part only.

### C. Datafiles Explanation (Folder: FFTBasedNN/dataset) ###

Store the image datasets for training and validation in the FFTBasedNN/dataset folder. Subfolders should be named after activity categories, with images placed directly inside each subfolder. This setup ensures the code runs correctly.

## V. SOME THINGS TO NOTE ##

**(1) Reproducibility Issues:** The network model receives image inputs in the form of three-channel RGB images. 

**(2) Environment Issues:** The project consists of both MATLAB and Python code. The recommended MATLAB version is R2025a and above, and the recommended Python version is 3.7 and above. The program is executed by the GPU environment.

**(3) Algorithm Design Issues:** The simulation software only supports MATLAB Runtime R2025a. Ensure that the support libraries are installed correctly. Within the network, the Body Block is repeated three times, which increases the number of parameters and the computational load during forward inference but enhances feature extraction performance. To accelerate network iteration, reducing the number of blocks to two or even one remains viable.

**(4) Right Issues: ⭐The project is limited to learning purposes only. All the code of the simulator is my own original. Any use or interpretation without authorized by me is not allowed!⭐**

Last but not least, hope that my work will bring positive contributions to the open source community in the filed of radar signal processing.

## VI. VERSION MANAGEMENT ##

| Version | Release Date | Description |
| ----------- | ----------- | ----------- |
| V1.0 | 2025.09.08 | The very version of the simulator. |
